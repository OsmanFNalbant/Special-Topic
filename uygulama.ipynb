{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15459658-cf93-48ad-822e-2237589a1777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "import librosa\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from joblib import load\n",
    "\n",
    "# Modeli yükle\n",
    "model_path = 'C:\\\\Users\\\\osman\\\\Desktop\\\\Notebook Workspace\\\\emotion_model.h5'  # Model dosyanızın yolu\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Scaler dosyasını yükle\n",
    "scaler_file = 'C:\\\\Users\\\\osman\\\\Desktop\\\\Notebook Workspace\\\\scaler.pkl'  # Scaler dosyasının yolu\n",
    "loaded_scaler = load(scaler_file)\n",
    "\n",
    "# Ses kaydetme fonksiyonu\n",
    "def record_audio(duration=2.5, sample_rate=22050, file_name='recorded_audio.wav'):\n",
    "    print(\"Recording audio...\")\n",
    "    audio_data = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, dtype='float32')\n",
    "    sd.wait()  # Kayıt bitene kadar bekle\n",
    "    write(file_name, sample_rate, (audio_data * 32767).astype(np.int16))  # WAV dosyası olarak kaydet\n",
    "    print(f\"Recording finished. Saved as {file_name}\")\n",
    "    return file_name\n",
    "\n",
    "# Özellik çıkarım fonksiyonu\n",
    "def extract_features_for_test(file_path, loaded_scaler, sample_rate=22050):\n",
    "    data, sr = librosa.load(file_path, duration=2.5, offset=0.6)\n",
    "    mfcc = librosa.feature.mfcc(y=data, sr=sr, n_mfcc=20)\n",
    "    mfcc_processed = np.mean(mfcc.T, axis=0)\n",
    "    mfcc_processed = mfcc_processed.reshape(1, -1)\n",
    "    mfcc_scaled = loaded_scaler.transform(mfcc_processed)\n",
    "    mfcc_scaled = np.expand_dims(mfcc_scaled, axis=2)\n",
    "    return mfcc_scaled\n",
    "\n",
    "# Tahmin fonksiyonu\n",
    "def test_audio_model(file_path, model, loaded_scaler):\n",
    "    features = extract_features_for_test(file_path, loaded_scaler)\n",
    "    prediction = model.predict(features)\n",
    "    predicted_class = np.argmax(prediction, axis=1)\n",
    "    emotion_labels = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad']\n",
    "    predicted_emotion = emotion_labels[predicted_class[0]]\n",
    "    return predicted_emotion, prediction[0]\n",
    "\n",
    "# UI fonksiyonu\n",
    "def run_prediction():\n",
    "    file_name = record_audio(duration=2.5, sample_rate=22050, file_name='recorded_audio.wav')\n",
    "    predicted_emotion, confidence_scores = test_audio_model(file_name, model, loaded_scaler)\n",
    "\n",
    "    result_text = f\"Predicted Emotion: {predicted_emotion}\\n\"\n",
    "    result_text += \"Confidence Scores:\\n\"\n",
    "    emotion_labels = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad']\n",
    "    for label, score in zip(emotion_labels, confidence_scores):\n",
    "        result_text += f\"{label}: {score:.4f}\\n\"\n",
    "\n",
    "    messagebox.showinfo(\"Prediction Result\", result_text)\n",
    "\n",
    "# Tkinter GUI\n",
    "root = tk.Tk()\n",
    "root.title(\"Emotion Recognition\")\n",
    "\n",
    "# Record Button\n",
    "record_button = tk.Button(root, text=\"Record and Predict\", command=run_prediction, height=2, width=20)\n",
    "record_button.pack(pady=20)\n",
    "\n",
    "# Start the GUI loop\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
